{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* eda\n",
    "* prepare dataset for bert formet\n",
    "    * add special tokens to the **start** and **end** of each sentence\n",
    "    * pad and truncate\n",
    "    * care about `mask`, `id`,... (1 for token, 0 for pad)\n",
    "* finetuning\n",
    "* ensemble\n",
    "---\n",
    "Know the difference among\n",
    "* tokenizer\n",
    "* special token\n",
    "* attributes of token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exploring the pre-trained BERT model\n",
    "* Extracting embeddings from pre-trained BERT\n",
    "* Extracting embeddings from all encoder layers of BERT\n",
    "* Fine-tuning BERT for downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "# model = RobertaModel.from_pretrained('roberta-base')\n",
    "# model.save_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./model/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.32.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file ./model/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing RobertaModel.\n",
      "\n",
      "All the weights of RobertaModel were initialized from the model checkpoint at ./model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# tokenizer.save_pretrained('./tokenizer')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('./tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'Ġlove', 'ĠParis']\n",
      "['<s>', 'I', 'Ġlove', 'ĠParis', '</s>']\n",
      "['<s>', 'I', 'Ġlove', 'ĠParis', '</s>', '<pad>', '<pad>']\n",
      "[1, 1, 1, 1, 1, 0, 0]\n",
      "[0, 100, 657, 2201, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I love Paris\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)\n",
    "tokens = ['<s>'] + tokens + ['</s>']\n",
    "print(tokens)\n",
    "tokens = tokens + [\"<pad>\"] * 2\n",
    "print(tokens)\n",
    "attention_mask = [1 if i != \"<pad>\" else 0 for i in tokens ]\n",
    "print(attention_mask)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(token_ids).unsqueeze(dim = 0) \n",
    "# why do we need to unsqueeze at dim = 0 ?\n",
    "# because we have 1 sentence, that's mean our batch_size is 1\n",
    "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "attention_mask = torch.tensor(attention_mask).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(token_ids, attention_mask = attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "outputs.last_hidden_state.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_rep, cls_head = outputs[0], outputs[1]\n",
    "print(hidden_rep.shape)\n",
    "print(cls_head.shape)\n",
    "# [1,7,768] ~ [batch_size, sequence_length, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_rep[0][0].shape \n",
    "# 768\n",
    "# với mỗi batch, ta có 1 câu (sequence_length = số token + pad)\n",
    "#  tensor có torch.Size([768]) là biểu diễn của 1 token\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
